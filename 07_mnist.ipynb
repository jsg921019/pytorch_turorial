{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torchvision.dataset에서 여러 dataset을 받을 수 있음\n",
    "  * `root` : 디렉토리\n",
    "  * `train` : True 면 훈련데이터 False면 테스트데이터\n",
    "  * `transform` : 적용할 transform\n",
    "  * `download` : 없으면 download\n",
    "* attributes\n",
    "  * `dataset_train.data` : 데이터\n",
    "  * `dataset_train.targets` : 레이블\n",
    "  * `dataset_classes` : 클래스 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = torchvision.datasets.MNIST(root='', train=True, transform=transforms.ToTensor())\n",
    "dataset_test = torchvision.datasets.MNIST(root='', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = dataset_train[0]\n",
    "plt.imshow(X[0], cmap='Greys')\n",
    "plt.title(f'label: {y}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.layer = nn.Linear(28*28, 10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "epoch 1    training loss:0.537    training acc:86.533    test loss:0.362    test acc:90.290\n",
      "epoch 2    training loss:0.359    training acc:90.077    test loss:0.324    test acc:91.250\n",
      "epoch 3    training loss:0.331    training acc:90.775    test loss:0.309    test acc:91.600\n",
      "epoch 4    training loss:0.316    training acc:91.162    test loss:0.298    test acc:91.750\n",
      "epoch 5    training loss:0.307    training acc:91.443    test loss:0.293    test acc:91.910\n",
      "epoch 6    training loss:0.300    training acc:91.590    test loss:0.289    test acc:92.040\n",
      "epoch 7    training loss:0.295    training acc:91.792    test loss:0.286    test acc:92.100\n",
      "epoch 8    training loss:0.291    training acc:91.898    test loss:0.284    test acc:92.120\n",
      "epoch 9    training loss:0.287    training acc:91.980    test loss:0.280    test acc:92.100\n",
      "epoch 10    training loss:0.284    training acc:92.105    test loss:0.281    test acc:92.150\n",
      "epoch 11    training loss:0.282    training acc:92.205    test loss:0.277    test acc:92.120\n",
      "epoch 12    training loss:0.280    training acc:92.190    test loss:0.276    test acc:92.350\n",
      "epoch 13    training loss:0.278    training acc:92.273    test loss:0.275    test acc:92.320\n",
      "epoch 14    training loss:0.276    training acc:92.352    test loss:0.275    test acc:92.180\n",
      "epoch 15    training loss:0.274    training acc:92.322    test loss:0.274    test acc:92.170\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "lr = 0.1\n",
    "\n",
    "model = SimpleClassifier().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print('Start training...')\n",
    "\n",
    "for epoch in range(1, training_epochs+1):\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_correct = 0\n",
    "    \n",
    "    for X, y in dataloader_train:\n",
    "        X, y = X.view(-1,28*28).to(device), y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_loss += loss.item()\n",
    "            running_correct += sum(y_pred.argmax(dim=1) == y)\n",
    "    \n",
    "    running_test_loss = 0\n",
    "    running_test_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader_test:\n",
    "            X, y = X.view(-1,28*28).to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            running_test_loss += loss.item()\n",
    "            running_test_correct += sum(y_pred.argmax(dim=1) == y)\n",
    "    \n",
    "    print(f'epoch {epoch}\\\n",
    "    training loss:{running_loss/len(dataloader_train):.3f}\\\n",
    "    training acc:{running_correct/len(dataloader_train):.3f}\\\n",
    "    test loss:{running_test_loss/len(dataloader_test):.3f}\\\n",
    "    test acc:{running_test_correct/len(dataloader_test):.3f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
