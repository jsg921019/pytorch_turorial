{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.random.rand(100)*10\n",
    "y_ = 2 * x_ + 10 + np.random.randn(100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAW6klEQVR4nO3db4xc1XnH8d8zu96A848FDDEstsOf0gBVYb0lTqkaCElEWhoSXBJImlgViXnhtKFBaigvCKVvqJS/L6xIDpBQ1bgB7AhkJW2oa5Skit3sbGjBdSmWy5olG2zI0JAaZb07T1/MzDI7O3fmzsz9M3fu9yNZu3Nn1nNGNj+On/ucc8zdBQDInkLaAwAAdIcAB4CMIsABIKMIcADIKAIcADJqOMk3O/30033dunVJviUAZF6xWHzJ3Vc1Xk80wNetW6fJyckk3xIAMs/Mpptdp4QCABlFgANARhHgAJBRBDgAZBQBDgAZRYADQEYR4AAQg+J0SVv3HlJxuhTbeyTaBw4AeVCcLunj9+7T3HxZI8MFbf/UBq1fOxr5+zADB4CI7Tv8submyyq7dGK+rH2HX47lfdoGuJmdZGb/Zmb/bmYHzOyvq9dPNbPHzezZ6tfo//cCABm04dzTNDJc0JBJK4YL2nDuabG8T5gSyq8lvcfdf2VmKyT9yMy+J+l6SXvc/R4zu13S7ZI+H8soAaDPFKdL2nf4ZW0497Rl5ZH1a0e1/VMbAp+PStsA98qZa7+qPlxR/eWSrpN0ZfX6A5KeEAEOYMAVp0vaNTWjhyef13zZA2vc69eOxhbcNaFq4GY2ZGZPSjoq6XF33y/pTHeflaTq1zMCfnazmU2a2eSxY8eiGjcAJK52c/LB/Uc0t+Cx17jbCRXg7r7g7pdKGpN0uZldEvYN3H2bu0+4+8SqVct2QwSAzKjdnKwdBW+Kt8bdTkdthO7+ipk9IekaSS+a2Wp3nzWz1arMzgFgYNVuTp6YL2toqKA/Xj+mjeNjbUslrerlvWgb4Ga2StKJanifLOm9kv5W0mOSNkm6p/r10chGBQB9qHZzcufUjEzS9SHDO66e8DAz8NWSHjCzIVVKLg+5+24z+7Gkh8zsZklHJN0QyYgAoM/tmprR3HxZO6dm2gZys57wxALc3f9D0mVNrr8s6epIRgEAfSao7NFpINeXXaKul7OUHgAatCp7dBrIcfaEE+AA0KDVLLubQI6rJ5wAB4AGjbPs0ZUj2rr30GJgJ7FIJwwCHEDuNda762fZoytHdPfuA7HvLNgNAhxArgXVu2u/tu49FFsXSa/YThZArrXa+rU4XdILr7ym4aH4dxbsBjNwALkW1FVSPzMfLphuvHxNqIU7SSLAAeRKq3p3fVdJ/cx8oew665ST+yq8JQIcQI60q3fXi3MBTlQIcAC50aq/uzhdWrbHSRKHMvSCAAeQG63q3Tdt+7HmFiobxT5cnNGOT2/om37vIAQ4gNxoVe8+seCLr+u3dsEgBDiAXAmqd68YssUZeL/WvBsR4AByb/3aUe3Y/K6O9vnuBwQ4ACiZQ4ijxkpMAMgoAhwAMooAB4CMIsABIKMIcACZVZwuaeveQypOl9IeSiroQgGQGfUbUUkKPLcyLwhwAJnQuBHVxvGxvj1oISmUUABkQuNGVC5pZLg/D1pICjNwAJnQuBHVxvExbRwf6+vdAuNGgAPIhKCNqPIY3DUEOIDMqN89sP5xvcYTdwYZAQ6gZ0mFZtCJOmGfHzQEOICeJBmarU7UCfP8oKELBUBPmoVmo6gW3NRuZAZ1nrR7ftAwAwfQk3aH/0Y5Q293TmUWzrGMEgEOoCftQjPqska7fbuzuK93twhwAD1rFZqjK0dUMJPcc1HWSBI1cACxKU6XdPfuAyq7q1Aw3XntxbmZHSeBGTiA2NSXT0yu0vG5tIc0UJiBA4hN3rpCksYMHEBs8tYVkjQCHECs8tQVkjRKKACQUW0D3MzOMbO9ZnbQzA6Y2Wer1+8ysxfM7Mnqrz+If7gA0pT3I8z6TZgSyryk29x9yszeLKloZo9Xn/uKu38xvuEB6Bd52ygqC9rOwN191t2nqt+/KumgpLPjHhiA/tJuz5N2s3Nm79Hr6Camma2TdJmk/ZKukPQZM/ukpElVZun8yQADqtWeJ2zzmo7QNzHN7E2Sdkq61d1/Kenrks6TdKmkWUlfCvi5zWY2aWaTx44di2DIANJQawn83PsvXBbA7WbnYXYsROdCzcDNbIUq4b3d3XdJkru/WPf8NyTtbvaz7r5N0jZJmpiY8F4HDCA9QS2B7XYkbPc8utM2wM3MJN0n6aC7f7nu+mp3n60+/LCkp+MZIoB+xzav6TD31pNiM/s9ST+U9JSkcvXyHZJuUqV84pKek3RLXaA3NTEx4ZOTkz0OGQDyxcyK7j7ReL3tDNzdfyTJmjz13SgGBgDoDisxASCjCHAAPaPHOx1sZgWgJ/R4p4cZOJAzUc+W6fFODzNwIEfimC3T450eAhzIkahPiJfo8U4TAQ7kSFyzZQ5tSAcBDgy44nRpyeyY2fLgIMCBARZU8ya4BwNdKMAAC9MhQg93djEDBwZYu5o3PdzZRoADA6xZzbu+Jh5HVwqSQ4ADA66+5t04477z2ovp4c4wAhzIkcYZd+n4HF0pGUaAA32usQ2wF81q4nSlZBcBDvSxsDcZw4Y8feCDhQAH+liYm4yddpIw4x4cBDjQJ5rNolu1AdZe/7NXXqOTJKcIcKAPtFox2azkUf/64YJpeKighQU6SfKGAAf6QKtSSbOSR/3rF8quj15+js4+5WTq2jlDgAN9oNNdAhtfv3F8jODOIXP3xN5sYmLCJycnE3s/IAtqtezRlSMqHZ8LPYuOsr0Q/c3Miu4+0XidGTgQkW4CtZe9SOgmAQEORKDbIGYvEvSC7WSBCNQH8dyJsr76z/8duD1r/fattVr2kIkOEnSMGTgQgVoQz50oqyzpXw+9pJ8894tlM/FmM3VWRqJbzMCBCNT6ta+44HQVTIEHKASVTLZcdT7hjY4R4EBE1q8d1a3v/Y2WJRFKJogSbYRAxNp1o9D+h07RRggkpF17H+1/iAolFADIKAIcADKKAAc6VN/HHeY6EBdq4EAHglZc9rIkHugWM3CgA836uFtdB+JEgAMdCOrjpr8baaAPHOhQUB83/d2IS1AfOAEOdInARlJYyAP0oDGsuWmJftA2wM3sHEl/J+ltksqStrn718zsVEnflrRO0nOSPuLu9E9h4DQLa/bxRj8IcxNzXtJt7v4OSRskbTGziyTdLmmPu18gaU/1MZA57fq3m4U1Ny3RD9rOwN19VtJs9ftXzeygpLMlXSfpyurLHpD0hKTPxzJKICZhSiHNDhyubR9LDRxp6qgGbmbrJF0mab+kM6vhLnefNbMzAn5ms6TNkrRmzZpexgpELkwpJCis2ZQKaQsd4Gb2Jkk7Jd3q7r80s1A/5+7bJG2TKl0o3QwSiEuz2XWz7hLCGv0oVICb2QpVwnu7u++qXn7RzFZXZ9+rJR2Na5BAXBpn15LoLkFmtL2JaZWp9n2SDrr7l+ueekzSpur3myQ9Gv3wgPjVH2nGknhkSZgZ+BWSPiHpKTN7snrtDkn3SHrIzG6WdETSDfEMEehMs57t+hl2q1WUr752QgUzyZ3uEvS9MF0oP5IUVPC+OtrhAL0pTpd00zf2Lda07/qji3X37gOamy9reKgguWu+7E13Evz1ibJclb/sQwXTnddeTPkEfY3NrDBQdk3NaG6+EsRz82V9+ydHlpRETix44E6CtTvsLsndVTo+l9bHAEIhwDFQGtucznzLSYsLboaHTAWTCgE7Cdb+Y2h8HuhX7IWCgbJxfEyPTD6vEwuuFUOmW959nm5593naNTWjhyefV9mXl0fqO1FGV46odHyOxTnIBAIcmdSsV7t27a4PXrIshPcdflnzZQ8sj9DnjSwiwJE5zZa/S637t5st2AGyjgBH5gT1ardaEs/eJRhEBDj6SphDEmqz6bn5ssxMoytHdOHb3tx2hk2ZBIOGE3nQNzo5JOHB/Ud056NPa6HsesOK18sozLAxiIJO5KGNEH2jk2XspeNzKnvlpmR9yaS2JB7IAwIcfaOTQxI4UAGgBo6UNda8w95o5KYkQIAjRUHtgJL0zM9fbRvO3JRE3hHgSE1jzXvn1MziXiZlr2wqVbtBSVADy1EDR2oa69im13u5JS25QQlgOWbgiF1Qb3ez03B21s3AC+IGJdAKAY5YBfV214f6lqvOX3w9m0oB4RHgiFVQb3fQgh1uTALhUQNHZB7cf0SfuG+/Htx/ZPFas35tzp0EosEMHJF4cP8R3fGdpyRJP3z2JUnSx965JrBfm50Bgd4R4IjE956eXfb4Y+9cI6l5WWTj+Ji8+pWSCdAdAhw9K06XdNKKoSXXPnDJ6sDX1te/N46PJTFEYCAR4OhJfSAPF6SLz3qrPvo7axZn342a1b+ZgQPd4SYmQilOl7R17yEVp0tLrtcHsrv0/ovfFhjeEptQAVFiBo62Wu3T3elRZWxCBUSHAEdbrcoe3QQyvd5ANAhwtNVulk0gA+kgwNFWsz1L7vjOUzJJ19MGCKSGAEdHnvn5q7rrsac1t1DZMvDh4ox2fJrtXoE0EOBoqn6zKen1vUsKZpovv34Qdn1NPMyJ8gCiQ4Bjmcauk+vHx+r26XYNmVSdgKtQMI2uHOnoRHkA0aAPPOea9Xc3dp2YtNi7PTJc0N986Lf0vovO1FDBVC677t59YMlJOmxQBSSDGXiOBc2aG7tOrh8f0/XjY0vKI6Xjc9pz8MXFU3NcbFAFJI0Az7Gg/u5a18muqRnVqt2NrYKNIX/JWW+VJDpTgAQR4DnWrr/74eKMTsyX9UiTTpP61sLRlSO6e/eBJTVzAPGjBp5jtRD+3PsvXHbTsVbTdlUOGt41NdP057dcdb5Kx+eofwMpIMBzrhbCkpbczPSG1zU+rscGVUA6KKGg6c3MjeNjemTyeZ1YcK0Yspb7drNBFZAOAhxNb2Zuuep87dj8rtChzH4oQPII8AHSzUrI4nRJL7zymoaHClpYWHozk1AG+lvbADez+yVdK+mou19SvXaXpE9LOlZ92R3u/t24Bon2ulkJufQ0HdONl6+hBRDIkDA3Mb8l6Zom17/i7pdWfxHeKds5NaNfn+isE6S+dLJQdp11ysmEN5AhbQPc3X8g6RcJjAVdKk6X9Ejx9UU3QwUL1QlC9wiQbb3UwD9jZp+UNCnpNncvNXuRmW2WtFmS1qwJPisR3dt3+GXNL5QlVVZC3jBxTuiTcegeAbKr2z7wr0s6T9KlkmYlfSnohe6+zd0n3H1i1apVXb4dWqmfSb9hRWcrIWt94IQ3kD1dzcDd/cXa92b2DUm7IxsRFoXtKmEmDeRTVwFuZqvdfbb68MOSno5uSJA67yqh5Q/InzBthDskXSnpdDObkfQFSVea2aWqrLB+TtItMY4xl1qdBA8AUogAd/ebmly+L4axoE67nQIBgJWYfWzj+Ji8+pXZN4BGBHgfaqx/t9pICkB+EeB9pNZ18sIrr1H/BtAWAd4nluxLMlTQcMG0UHbq3wACEeAJC+rtXrIvyUJZN16+RmedcnLPfd3d7FAIIBsI8AS16u1udhJ8r4HbzQ6FALKDAE9Qq97uOFZT0ksODDYCPEEbzj1Nw0OVWfbQ0PLadv1qyihKH/SSA4ONAI9By/B1X/K12WujKn2wRwow2AjwiDULX0mL7YHzZZercoDCzqkZ7ZqaWRbUUZY+2CMFGFwEeMQaw7c+pBvbA01qGtSUPgCEQYD3qLEE0hi+9SHd2B4oVY5CawxqSh8AwiDAexBUq64PX2lpSDe2BwYFNaUPAO0Q4D0IqlU3hm+r2TRBDaBbBHgPwtaqawFdOymewAYQBQK8B0G16sa6OCsiAcSBAA+hVV93YwmkWVizIhJAHAjwNjqdPTcLa9oCAcSBAG+j09lzs7CmLRBAHAjwqqAySWMgj64c0da9hwKDOCis6TYBEDXz2t4cCZiYmPDJycnE3i+sdmWSWriPrhzR3bsPcDMSQKLMrOjuE43XC2kMpt80K5PUW792VFuuOl+l43MtXwcASSLA9XqZZMjU8iZj2NcBQBIooVQFbesa5hoAxCmohMJNzKow/dzNlskDQFoooQRoVxcHgLQR4AGodwPod5RQArD4BkC/I8BboN4NoJ9RQgGAjBq4AC9Ol7R17yEVp0uRvA4A+tVAlVDC7hzI/twABsFAzcDDtv7RIghgEAxUgLMkHkCeZGYpfdgl7FG/DgDSluml9EE162YhHLb1jxZBAFmXiQAPqllzIxJAnmWiBt6sZs2NSAB5l4kZeNCydg4KBpBnbQPczO6XdK2ko+5+SfXaqZK+LWmdpOckfcTdY1sRE1TrZq8SAHkWpoTyLUnXNFy7XdIed79A0p7q41jUbmB+6fvP6OP37ltcOUkXCYC8azsDd/cfmNm6hsvXSbqy+v0Dkp6Q9PkIx7WIG5gA0Fy3NzHPdPdZSap+PSPohWa22cwmzWzy2LFjHb8RNzABoLnYb2K6+zZJ26TKQp5Of75W6941NaPaD9dCnRuYAPKs2wB/0cxWu/usma2WdDTKQTWzc2pGc/Nl7Zqa0fZPbeAGJoDc67aE8pikTdXvN0l6NJrhNNesZLJ+7ai2XHU+4Q0gt9oGuJntkPRjSRea2YyZ3SzpHknvM7NnJb2v+jg2bD4FAMuF6UK5KeCpqyMeSyB6vgFguUysxJTYfAoAGmViLxQAwHIEOABkFAEOABlFgANARhHgAJBRBDgAZFSihxqb2TFJ01386OmSXop4OFmQx8/NZ86PPH7ubj/zWndf1Xgx0QDvlplNNjuRedDl8XPzmfMjj5876s9MCQUAMooAB4CMykqAb0t7ACnJ4+fmM+dHHj93pJ85EzVwAMByWZmBAwAaEOAAkFF9H+Bmdo2ZPWNmh8zs9rTHEzczO8fM9prZQTM7YGafTXtMSTGzITP7qZntTnssSTGzU8zsETP7r+qf+bvSHlPczOwvqn+3nzazHWZ2UtpjioOZ3W9mR83s6bprp5rZ42b2bPVrT3tk93WAm9mQpK2SPiDpIkk3mdlF6Y4qdvOSbnP3d0jaIGlLDj5zzWclHUx7EAn7mqR/dPfflPTbGvDPb2ZnS/pzSRPufomkIUk3pjuq2HxL0jUN126XtMfdL5C0p/q4a30d4JIul3TI3Q+7+5ykf5B0XcpjipW7z7r7VPX7V1X5D/rsdEcVPzMbk/SHku5NeyxJMbO3SPp9SfdJkrvPufsr6Y4qEcOSTjazYUkrJf0s5fHEwt1/IOkXDZevk/RA9fsHJH2ol/fo9wA/W9LzdY9nlIMwqzGzdZIuk7Q/3ZEk4quS/lJSOe2BJOhcScckfbNaOrrXzN6Y9qDi5O4vSPqipCOSZiX9r7t/P91RJepMd5+VKpM1SWf08pv1e4Bbk2u56Hs0szdJ2inpVnf/ZdrjiZOZXSvpqLsX0x5LwoYljUv6urtfJun/1OM/qftdteZ7naS3SzpL0hvN7E/SHVV29XuAz0g6p+7xmAb0n1v1zGyFKuG93d13pT2eBFwh6YNm9pwqZbL3mNnfpzukRMxImnH32r+wHlEl0AfZeyX9j7sfc/cTknZJ+t2Ux5SkF81stSRVvx7t5Tfr9wD/iaQLzOztZjaiys2Ox1IeU6zMzFSpiR509y+nPZ4kuPtfufuYu69T5c/4X9x94Gdl7v5zSc+b2YXVS1dL+s8Uh5SEI5I2mNnK6t/1qzXgN24bPCZpU/X7TZIe7eU36+tT6d193sw+I+mfVLlbfb+7H0h5WHG7QtInJD1lZk9Wr93h7t9NcUyIz59J2l6doByW9KcpjydW7r7fzB6RNKVKx9VPNaBL6s1sh6QrJZ1uZjOSviDpHkkPmdnNqvzP7Iae3oOl9ACQTf1eQgEABCDAASCjCHAAyCgCHAAyigAHgIwiwAEgowhwAMio/wdPvBz2PuPwSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_, y_, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H(x) = Wx + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(X):\n",
    "    return W * X + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSEloss(y_pred, y):\n",
    "    return torch.mean((y_pred-y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\nabla W = \\frac{\\partial cost}{\\partial W} = \\frac{2}{m} \\sum^m_{i=1} \\left( Wx^{(i)} - y^{(i)} \\right)x^{(i)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ W := W - \\alpha \\nabla W $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(params, lr=0.01):\n",
    "    with torch.no_grad(): # do not calculate gradient in this block\n",
    "        for param in params:\n",
    "            param -= lr * param.grad.data\n",
    "            param.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100: loss = 8.588  W = 2.890  b = 4.347\n",
      "epoch 200: loss = 3.189  W = 2.532  b = 6.608\n",
      "epoch 300: loss = 1.272  W = 2.319  b = 7.956\n",
      "epoch 400: loss = 0.591  W = 2.192  b = 8.758\n",
      "epoch 500: loss = 0.350  W = 2.117  b = 9.237\n",
      "epoch 600: loss = 0.264  W = 2.072  b = 9.522\n",
      "epoch 700: loss = 0.233  W = 2.045  b = 9.691\n",
      "epoch 800: loss = 0.223  W = 2.029  b = 9.793\n",
      "epoch 900: loss = 0.219  W = 2.019  b = 9.853\n",
      "epoch 1000: loss = 0.217  W = 2.014  b = 9.889\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor(x_)\n",
    "y = torch.Tensor(y_)\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True) # needs autograd for backpropation\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.SGD([W, b], lr=0.01) # updating algorithm\n",
    "\n",
    "epochs = 1000\n",
    "for i in range(epochs):\n",
    "    \n",
    "    y_pred = LinearRegression(X)\n",
    "    loss = MSEloss(y_pred, y)\n",
    "    loss.backward()\n",
    "    gradient_descent([W, b])\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f'epoch {i+1}: loss = {loss:.3f}  W = {W.item():.3f}  b = {b.item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pytorch modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100: loss = 7.467  W = 2.829  b = 4.735\n",
      "epoch 200: loss = 2.791  W = 2.496  b = 6.839\n",
      "epoch 300: loss = 1.130  W = 2.297  b = 8.093\n",
      "epoch 400: loss = 0.541  W = 2.179  b = 8.840\n",
      "epoch 500: loss = 0.332  W = 2.109  b = 9.286\n",
      "epoch 600: loss = 0.258  W = 2.067  b = 9.551\n",
      "epoch 700: loss = 0.231  W = 2.042  b = 9.709\n",
      "epoch 800: loss = 0.222  W = 2.027  b = 9.803\n",
      "epoch 900: loss = 0.218  W = 2.018  b = 9.859\n",
      "epoch 1000: loss = 0.217  W = 2.013  b = 9.893\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor(x_).unsqueeze(1)\n",
    "y = torch.Tensor(y_).unsqueeze(1)\n",
    "\n",
    "model = LinearRegression()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 1000\n",
    "for i in range(epochs):\n",
    "    \n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        W, b = list(model.parameters())\n",
    "        print(f'epoch {i+1}: loss = {loss:.3f}  W = {W.item():.3f}  b = {b.item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H(X) = XW + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.random.rand(100, 5) * 10\n",
    "y_ = x_ @ np.array([0.1, 0.2, 0.3, 0.4, 0.5]) + 10 + np.random.randn(100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(5, 1) # input dimension 만 바뀜\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1000: loss = 2.567  W = [0.34842396 0.37391397 0.48941836 0.61965036 0.76563925]  b = 4.014\n",
      "epoch 2000: loss = 1.043  W = [0.25187078 0.30679157 0.41900432 0.5211035  0.66027004]  b = 6.447\n",
      "epoch 3000: loss = 0.501  W = [0.19432724 0.26678813 0.37703907 0.46237174 0.59747225]  b = 7.897\n",
      "epoch 4000: loss = 0.309  W = [0.16003287 0.24294719 0.35202906 0.42736924 0.5600465 ]  b = 8.761\n",
      "epoch 5000: loss = 0.241  W = [0.13959418 0.2287385  0.33712357 0.4065085  0.53774154]  b = 9.276\n",
      "epoch 6000: loss = 0.217  W = [0.1274133  0.2202705  0.3282403  0.3940761  0.52444845]  b = 9.583\n",
      "epoch 7000: loss = 0.208  W = [0.12015361 0.21522367 0.32294595 0.38666654 0.51652586]  b = 9.766\n",
      "epoch 8000: loss = 0.205  W = [0.1158271  0.21221597 0.31979078 0.38225067 0.5118044 ]  b = 9.875\n",
      "epoch 9000: loss = 0.204  W = [0.11324874 0.21042353 0.31791046 0.3796191  0.5089906 ]  b = 9.940\n",
      "epoch 10000: loss = 0.203  W = [0.11171208 0.20935528 0.31678984 0.37805068 0.5073136 ]  b = 9.979\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor(x_)\n",
    "y = torch.Tensor(y_).unsqueeze(1)\n",
    "\n",
    "model = MultivariateLinearRegression()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.004)\n",
    "\n",
    "epochs = 10000\n",
    "for i in range(epochs):\n",
    "\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 1000 == 0:\n",
    "        W, b = list(model.parameters())\n",
    "        print(f'epoch {i+1}: loss = {loss:.3f}  W = {W.detach().numpy()[0]}  b = {b.item():.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
